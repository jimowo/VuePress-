---
title: 面经整理
author: jimowo
icon: write
date: 2023-08-20
order: 3
category:
  - 面经
tag:
  - Java
---

# 面经整理

## Java基础

### Java中的继承和多态 接口和抽象类的区别 StringBuffer和StringBuilder的区别

- 继承和多态

  继承是子类继承父类的除了静态方法和静态字段的所有方法和字段。
  多态分为类的多态和方法的多态。类的多态体现为继承，方法的多态体现为对方法的重载。

- 接口和抽象类的区别

  抽象类中可以有构造函数和非抽象方法，接口不能实例化，且所有方法都是抽象方法，jdk1.8中出现了default修饰的方法。接口中的所有成员变量都是public static final修饰的。
  接口是行为的抽象，cloneable之类的，是**Like A** 的关系；
  抽象类是类的抽象，是一种模板设计，是**Is A **的关系

- StringBuffer 和StringBuilder的区别

  StringBuilder线程不安全，效率比StringBuffer 高；
  StringBuffer的所有public 方法都是synchronized 修饰的。
  底层是默认长度为16的字符数组，每次扩容为数组原长度的2倍+2

### 说一下String内部结构，JDK9及之后的有什么变化

在**JDK9及之前**的版本中，String的内部使用**字符数组**来存储字符串的字符序列。通过char[]数组，可以按索引访问每个字符。

在JDK9中，引入了一个新的内部数据结构——紧凑字符串（Compact Strings）。对于拉丁字符（Latin-1字符集中的字符，包括大部分常用的英文字符），JDK9及之后的版本使用**字节数组**（byte[]）来存储。由于拉丁字符在编码时只需要占用一个字节，相比于使用字符数组存储，这样可以节省一半的空间。而对于非拉丁字符，仍然使用字符数组来存储。

紧凑字符串的引入主要是为了减少String对象的内存占用，尤其是在处理大量拉丁字符的场景下可以显著降低内存消耗。

### ArrayList和LinkedList区别

1. 内部实现：ArrayList是基于数组实现的动态数组，而LinkedList是基于双向链表实现的。
2. 插入和删除操作：对于ArrayList，插入和删除元素可能需要进行数组的扩容或移动操作，因为数组的长度是固定的。而LinkedList在插入和删除元素时，只需调整节点的指针，不需要像ArrayList那样进行大量的数据移动。
3. 随机访问效率：ArrayList可以通过索引直接访问元素，因为底层数组的连续存储特性。而LinkedList需要遍历链表才能找到指定位置的元素，所以随机访问效率比ArrayList低。

### 什么是泛型 泛型的作用 泛型的使用方式有哪几种

- 什么是泛型

  参数化类型，把类型参数化

- 泛型的作用

  代码重用：在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型。实现模板的效果

  类型安全：通过指定泛型类型参数，编译器可以在编译时检查代码的类型安全性，避免在运行时出现类型转换错误。

  减少类型转换：泛型可以避免繁琐的类型转换操作，提高代码的可读性和维护性。

- 泛型的使用方式

  泛型类：带有泛型类型属性的类 `List<T>`；
  泛型接口：带有泛型类型参数的接口 `Comparable<T>`；
  泛型方法：带有泛型类型参数的方法 `public <T> void printArray(T[] array)`

### HashMap的遍历方式有哪几种 ?HashMap与HashTable的区别? HashMap底层?(为什么是8和64没答出来 为什么选择红黑树这种数据结构 介绍一下红黑树)

- HashMap的遍历方式有哪几种 4种

  1. 使用 `keySet()` 方法遍历键（key）
  2. 使用 `values()` 方法遍历值（value）
  3. 使用 `entrySet()` 方法遍历键值对（entry）
  4. 使用迭代器（Iterator）遍历键值对

- HashMap与HashTable的区别

  1. HashTable线程安全
  2. HashMap允许键和值为null
  3. HashMap实现了Map接口，HashTable是Dictionary的子类
  4. `HashMap`可以指定初始容量和负载因子。当 `HashMap` 的元素数量超过负载因子与当前容量的乘积时，`HashMap` 会自动进行扩容。`HashTable` 在构造时只能指定初始容量，默认的负载因子是 0.75。扩容时，`HashTable` 的大小必须为素数，并且会创建一个新的数组来重新分配元素。

- HashMap底层原理

  数组 + 链表（红黑树） = 散列表

  存储结构：在将键值对存储到哈希表中时，需要经过哈希函数的计算来确定元素在数组中的位置。哈希函数将键对象映射为数组索引，使得元素能够均匀地分布在不同的桶中。（对于相同的键对象，哈希函数应该返回相同的哈希码）

  当多个键对象映射到同一个桶时（数组的同一个位置），HashMap 使用链表或红黑树来解决键冲突问题。当链表中的元素较少时，使用链表存储键值对；当链表中的元素较多时（默认阈值为 **8**），将链表转换为红黑树，以提高查找效率。

- HashMap为什么在链表长度大于8，且数组长度大于64时将链表转换为红黑树

  这是因为当链表长度过长时，使用链表进行查找的性能可能变得很差。链表的查找时间复杂度是O(n)，转化为[红黑树](https://so.csdn.net/so/search?q=红黑树&spm=1001.2101.3001.7020)后，查找的效率会比链表高，但是转化红黑树这个过程是耗时的，而且在扩容时还要对红黑树重新的左旋右旋保持平衡，相对耗时。所以需要到一定阈值时再转换。

  链表长度在大于8以后再出现hash碰撞的可能性几乎为0

  数组长度至少应为4 * TREEIFY_THRESHOLD

  当链表长度为8和数组长度为64再转换时，此时的hash碰撞概率已经很小接近0

### ConcurrentHashMap如何保证线程安全

1. 分段锁机制：ConcurrentHashMap将整个**哈希表分割成多个独立的段**（Segment），每个段内部维护一个类似于HashMap的数据结构。不同的线程可以同时访问不同的段，从而减小了并发操作的粒度，并发度更高。
2. 无阻塞操作：ConcurrentHashMap在进行插入、删除和更新等操作时，采用了无阻塞算法（**CAS**、volatile等），而不是传统的加锁机制。这样可以避免了线程之间的阻塞和等待，提高了并发性能。
3. 可见性保证：ConcurrentHashMap**使用volatile变量来保证多个线程之间的可见性**，确保读取到最新的数据。

### error和exception的区别 怎么处理exception

- error和exception的区别

  Error 是指程序无法处理的错误，虚拟机错误、栈溢出（SOF）、内存溢出（OOM）

  Exception 是指程序本身可以处理的异常（可以自己Throw）

- 怎么处理exception

  exception分为编译时异常和运行时异常，前者由编译器发现。后者可以通过throw和catch来自定义处理

### final关键字有什么作用

1. 修饰变量：当`final`关键字修饰一个变量时，该变量就成为一个常量，其值不能再被修改。一旦被初始化赋值后，就无法再改变。这样可以确保常量的值在使用过程中不会被意外修改，提高代码的可读性和安全性。
2. 修饰方法：当`final`关键字修饰一个方法时，该方法就不能被子类重写或覆盖。这样可以防止子类修改父类的行为，保护方法的稳定性和一致性。
3. 修饰类：当`final`关键字修饰一个类时，该类就不能被继承，即不能有子类。这样可以直接阻止其他类对该类的继承，保护类的完整性和安全性。
4. 修饰参数：当`final`关键字修饰方法的参数时，表示参数是只读的，即在方法内部不能对参数进行赋值操作。这样可以避免在方法内部意外修改参数的值，增强方法的可靠性和可理解性。

### volatile关键字有什么作用

1. 可见性：`volatile`关键字保证了多线程环境下的可见性。当一个变量被声明为`volatile`时，在一个线程修改了该变量的值后，其他线程能够立即看到最新的值，而不会使用缓存中的旧值。
2. 禁止指令重排序：`volatile`关键字可以防止指令重排序优化。在单线程环境中，编译器和处理器可能会对指令进行重排序，以提高执行效率。但在多线程环境中，指令重排序可能导致线程间操作顺序的错乱。通过使用`volatile`关键字，可以禁止编译器和处理器对被修饰变量相关指令的重排序，从而确保线程间操作的正确顺序。
3. 不能保证原子性：`volatile`关键字不能保证操作的原子性。例如，对一个`volatile`变量进行自增操作，虽然保证了可见性，但是多个线程同时进行自增操作仍然会产生竞态条件。要保证原子性，需要使用`synchronized`关键字或`java.util.concurrent.atomic`包中的原子操作类。

### Lambda表达式

是对匿名函数的简写形式

他的写法是使用一个`->`符号，左边写的是形参列表，右边就是对抽象方法的处理

- 无返回值有形参的抽象方法

  - 可以省略方法名，IDEA会帮你自动检测方法名；
  - 可以省略方法中的形参类型；
  - 如果对抽象方法的实现逻辑只有一行，可以省略方法体的大括号，当然如果不止一行，就不能省略了；

- 有返回值的抽象方法

  有返回值的方法，如果要去掉大括号，还需要去掉return关键字

- 有一个形参的抽象方法

  形参列表中只有一个参数，可以去掉形参的括号

- Lambda表达式也可以作为参数传递

- **Lambda表达式不是万能的，他需要函数式接口的支持**

  - 函数式接口的定义是: 只包含一个抽象方法的接口，称为函数式接口
  - 4大函数式接口
    1. `Consumer<T>`：该函数式接口接受一个输入参数，并对其进行操作，但没有返回结果。常用的方法是 `accept(T t)`，用于对给定的参数执行某些操作
    2. `Supplier<T>`：该函数式接口不接受任何输入参数，但返回一个结果。常用的方法是 `get()`，用于获取结果。
    3. `Function<T, R>`：该函数式接口接受一个输入参数，并将其转换为另一种类型的结果。常用的方法是 `apply(T t)`，用于对给定的参数进行处理并返回结果。
    4. `Predicate<T>`：该函数式接口接受一个输入参数，并返回一个布尔值结果。常用的方法是 `test(T t)`，用于对给定的参数进行条件判断。

### 通过静态工厂 Integer.valueOf(int) 来创建 Integer 对象有什么好处

如果我们通过静态工厂 Integer.valueOf(int) 来创建 Integer 对象，首先会判断创建的对象值是否在 IntegerCache 中有缓存，有的话直接取缓存中的值，否则通过标准对象创建语法 new Interger(int) 创建并返回。

所以默认情况下，如果使用 Integer.valueOf(int) 创建的 Integer 对象值在 -128 ～ 127 之间，那么无论创建多少次，创建的每一个对象使用`==` 关系操作符得到的结果都是`true`，否则都是`false`。

**注：如果修改过`java.lang.Integer.IntegerCache.high`属性值，那么结果就另当别论了。**

静态工厂 Integer.valueOf(int) 的设计正是对享元模式的应用

Integer.valueOf(int) 通过享元模式缓存频繁请求的值来显着提高空间和时间性能，效率远远高于通过 new Integer() 创建对象的方式。所以 Java 9 中直接弃用了new Integer()

## Java多线程

###  Java中实现多线程

1. 继承Thread类，重写run方法
2. 实现Runnable接口，把任务加入Thread类，启动（线程任务与线程控制分离）
3. 使用 Callable 和 Future：Callable 是一个带有泛型的接口，可以返回一个结果，并且可以通过 Future 对象来获取返回值。可以通过创建实现 Callable 接口的类，并实现其中的 `call()` 方法来定义线程的执行逻辑。然后使用 `ExecutorService` 提交 Callable 任务，并通过 Future 对象获取任务的返回结果。
4. 使用线程池：使用 Java 提供的线程池框架可以方便地管理和复用线程资源。通过创建 ExecutorService 对象，并调用其 `execute()` 方法或 `submit()` 方法来提交任务，线程池会自动分配可用的线程来执行任务

### Runnable、Callable 区别，如何接收这两个线程异常

- Runnable、Callable的区别
  1. 返回值：Runnable接口没有返回值，而Callable接口可以返回一个结果。
  2. 异常处理：Runnable接口的run()方法不能抛出受检异常，只能在方法内部进行异常处理；而Callable接口的call()方法**可以抛出受检异常**，并且可以将异常抛给调用者处理。
  3. 使用方式：Runnable接口通常用于创建可执行的线程任务，通过实现run()方法来定义线程执行的代码；而Callable接口则通常与ExecutorService（线程池）一起使用，通过返回Future对象来获取异步计算的结果。
- 如何处理Runnable任务的异常
  1. Runnable使用try-catch来捕获异常并处理
  2. 通过Thread类的`setUncaughtExceptionHandler()`方法设置一个全局的未捕获异常处理器，来处理在Runnable中抛出的异常。
  3. 如果使用ExecutorService来执行Runnable任务，可以通过Future对象的get()方法来获取任务执行过程中的异常信息。

### 如何创建一个线程池,拒绝策略有什么,怎么设置线程池的大小(动态修改)

- 如何创建一个线程池

  可以使用 JUC的`Executors` 类来创建线程池，并使用 `Executor` 类设置线程池的属性。

- 线程池拒绝策略

  拒绝策略是在线程池无法接受新任务时采取的一种策略

  1. `ThreadPoolExecutor.AbortPolicy`（默认）：直接抛出 `RejectedExecutionException` 异常，拒绝新任务的提交。
  2. `ThreadPoolExecutor.CallerRunsPolicy`：由调用线程处理该任务。即将任务返回给调用者进行处理。
  3. `ThreadPoolExecutor.DiscardPolicy`：静默地丢弃无法处理的任务，不给予任何提示。
  4. `ThreadPoolExecutor.DiscardOldestPolicy`：丢弃最早提交的任务，然后尝试再次提交新任务。

- 怎么动态修改线程池的大小

  可以使用 `ThreadPoolExecutor` 的 `setCorePoolSize()` 和 `setMaximumPoolSize()` 方法来动态修改线程池的大小

###  线程池7个参数？提交任务流程？为什么不先创建临时线程而是先放进阻塞队列？

- 线程池的7个参数

  1. corePoolSize（核心线程数）：线程池中始终保持活动状态的线程数，即使这些线程是空闲的。
  2. maximumPoolSize（最大线程数）：线程池中允许存在的最大线程数。
  3. keepAliveTime（线程空闲时间）：当线程池中的线程数量大于corePoolSize时，空闲线程在被回收之前等待新任务的最长时间。超过该时间，空闲线程会被销毁。
  4. unit（时间单位）：keepAliveTime的时间单位，例如：TimeUnit.SECONDS。
  5. workQueue（阻塞队列）：用于存放等待执行的任务的阻塞队列。线程池中的线程都从该队列中获取任务进行处理。
  6. threadFactory（线程工厂）：用于创建新线程的工厂。
  7. handler（拒绝策略）：当线程池和阻塞队列都已满，无法继续接受新任务时，该策略定义了如何处理这些被拒绝的任务。

- 提交流程

  1. 当调用线程池的execute或submit方法提交一个任务时，线程池会首先判断是否已经达到了**corePoolSize限制**，如果没有，则创建一个新线程来处理该任务。
  2. 如果当前线程池中的线程数量已经达到了corePoolSize限制，任务会被添加到**阻塞队列**中。
  3. 如果阻塞队列已满，但是还没有超过**maximumPoolSize限制**，线程池会创建一个新的**临时线程**来处理该任务。
  4. 如果线程池中的线程数已经达到了maximumPoolSize限制，且阻塞队列已满，这时会根据指定的**拒绝策略**来处理无法接受的任务，比如抛出异常、丢弃任务等。

- 上面的提交流程中为什么不先创建临时线程而是先放进阻塞队列

  通过将任务放入阻塞队列，可以实现流量控制，当任务数量暂时过多时，可以通过阻塞队列的容量限制来控制任务的接受速率，避免线程过度增长。

### 核心线程能否被回收

当使用了`allowCoreThreadTimeOut(true)`并且同时满足以下条件时，核心线程可能会被回收：

1. 当前线程池中的线程数大于核心线程数。
2. 核心线程在一段时间内都处于空闲状态，没有新的任务到来。

### 线程池配置无界队列了之后，拒绝策略怎么搞，什么时候用到无界对列



### volatile和sychronized的区别

1. 语义上的差异：
   - `volatile`关键字用于修饰变量，表示该变量在多线程环境下可能被其他线程修改，因此每次使用该变量时都要直接从主内存中获取最新的值。并且，对带有`volatile`关键字修饰的变量的写操作会立即刷新到主内存中，保证可见性。
   - `synchronized`关键字用于修饰方法或代码块，表示对其修饰的部分进行加锁，保证在同一时刻只有一个线程可以执行该方法或代码块，其他线程需要等待锁释放。
2. 内存语义：
   - `volatile`关键字提供了禁止指令重排序和保证可见性的功能，保证对其修饰的变量的修改对其他线程是可见的。但`volatile`不能保证原子性，不适用于复合操作。
   - `synchronized`关键字在加锁和释放锁过程中会自动进行线程间的内存同步，保证了原子性、可见性和有序性。

### synchronized锁升级过程和实现原理

- synchronized实现原理

  当线程尝试进入synchronized块时，首先会尝试获取对象的Monitor锁。如果Monitor锁未被占用，则当前线程获取到锁并执行临界区代码。如果Monitor锁已被别的线程持有，则当前线程会被阻塞，直到锁被释放。当线程退出synchronized块时，会释放Monitor锁。

- synchronized锁升级过程

  1. 偏向锁（Biased Locking）：初始状态下，对象的Mark Word字段为无锁状态。**当一个线程访问同步块时**，会检查对象的Mark Word是否为无锁状态，如果是，则使用CAS操作将Mark Word设置为指向当前线程的线程ID，并标记为偏向锁。之后该线程直接进入临界区执行，不需要进行同步操作。这样可以提高单线程访问临界区的性能。
  2. 轻量级锁（Lightweight Locking）：**当第二个线程尝试获取偏向锁失败时**，会升级为轻量级锁。轻量级锁使用CAS操作将对象头部的Mark Word替换为指向锁记录的指针，将锁记录中持有锁的线程ID设置为当前线程ID。此时，线程**通过CAS操作来竞争锁**。如果竞争成功，该线程进入临界区执行。如果竞争失败，表示存在竞争，锁会膨胀为重量级锁。
  3. 重量级锁（Heavyweight Locking）：当竞争轻量级锁的线程过多或**自旋次数达到一定阈值时，轻量级锁升级为重量级锁**。重量级锁会将线程置于阻塞状态，使用操作系统提供的互斥量（Mutex）来实现同步。此时，进入临界区的线程需要在释放锁之前进行阻塞和唤醒操作，效率较低。

### 讲讲jmm内存模型，volatile作用，实现原理，为什么 volatile 能防止指令重排，为什么有可见性问题

- JMM内存模型

  JMM（Java内存模型）是Java程序中定义了线程之间共享变量的可见性、有序性和原子性的规范。

  JMM通过以下机制来实现上述目标：

  1. 原子性：JMM保证对基本数据类型（除了long和double）的读写操作具有原子性。对于volatile修饰的变量，JMM保证了对它的读写具有原子性。
  2. 可见性：JMM通过在线程之间进行内存屏障（Memory Barrier）来实现可见性。读操作和写操作都有相应的内存屏障，用于刷新变量的值到主内存或者从主内存中读取最新值。
  3. 有序性：JMM通过内存屏障来禁止指令重排序，保证程序按照代码顺序执行。

- volatile作用，实现原理

  volatile关键字在Java中用于确保共享变量的可见性和禁止指令重排。

  1. 可见性：volatile关键字保证了一个线程对volatile变量的写操作对其他线程可见。当一个线程修改了volatile变量的值时，这个值将会立即被写入主内存，并且其他线程在读取该变量时会从主内存中获取最新值而不是工作内存中的副本。
  2. 禁止指令重排：当一个写操作对一个volatile变量进行写操作时，JVM会发出一条Lock前缀的指令，将该写操作变为原子操作，并且在写操作后增加一条**Store屏障**（Memory Barrier），这个屏障会强制刷新处理器缓存，使其他线程在读取该变量时能够获取最新值。

- 多线程操作的可见性问题

  可见性问题是因为多线程的操作都是在各自的工作内存中进行的，线程之间无法直接访问对方的工作内存。当一个线程修改了共享变量的值时，其他线程可能无法立即看到这个修改，而是继续访问自己工作内存中的变量副本。这是因为处理器会对内存进行缓存，为了提高效率，处理器可能将共享变量的值缓存在寄存器或者缓存中，并不及时更新到主内存中。

### ReentrantLock 实现原理，AQS实现原理

- ReentrantLock实现原理

  1. 基本结构：ReentrantLock内部使用了一个非公平的AQS（AbstractQueuedSynchronizer）来实现锁的功能。AQS是一个用于构建锁和同步器的框架，通过队列和等待/唤醒机制来管理线程的竞争和等待。
  2. 状态维护：ReentrantLock内部通过一个int类型的state来维护当前锁的状态。state的高16位表示持有锁的线程数，低16位表示当前等待获取锁的线程数。
  3. 获取锁：当一个线程尝试获取锁时，会先调用ReentrantLock的lock()方法。在lock()方法内部，会先尝试用CAS操作将state的高16位增加1。如果成功，表示当前线程获取到锁，可以直接进入临界区执行。如果失败，表示有其他线程持有锁，那么当前线程会进入同步队列中等待。
  4. 释放锁：当一个线程释放锁时，会调用ReentrantLock的unlock()方法。在unlock()方法内部，会先尝试用CAS操作将state的高16位减1。如果减少后的值为0，表示当前线程已经完全释放了锁。如果减少后的值大于0，表示当前线程还持有锁，可以继续执行临界区代码。在完全释放锁后，会通过唤醒操作将同步队列中的等待线程唤醒，并允许它们去竞争获取锁。
  5. 可重入性：ReentrantLock支持可重入锁，也就是同一个线程可以多次获取同一个锁。在同一个线程再次调用lock()方法时，会增加state的高16位，并记录当前线程已经获取锁的次数。在释放锁时，会减少state的高16位，直到最后一次释放锁为止。

- **AQS实现原理**

  AQS是依赖内部的同步队列实现，也就是**FIFO双向队列**，如果当前线程竞争锁失败，那么AQS会把当前线程以及等待状态封装成一个**Node节点**加入到同步队列中（`addWaiter()`方法），同时阻塞该线程，当同步状态释放时，会把首节点唤醒，使其再次尝试获取同步状态。

  AQS使用一个volatile修饰的int类型变量state来表示当前的同步状态。state的具体含义可以由使用者自行定义和扩展。例如，对于独占锁来说，state=0表示锁未被占用，state=1表示锁已被占用；对于共享锁来说，state表示锁的可用数量等。

  当一个线程尝试获取锁时，会调用AQS的acquire()方法。在acquire()方法内部，会先根据具体的实现逻辑判断当前线程是否能够直接获取锁。如果可以直接获取锁，则直接返回；否则，当前线程会被封装成一个Node节点加入到同步队列中，并进入自旋状态，不断尝试获取锁。

  当一个线程释放锁时，会调用AQS的release()方法。在release()方法内部，会根据具体的实现逻辑将state的值进行修改，并尝试唤醒同步队列中的等待线程。

### sychronized和ReentrantLock区别

1. 锁的获取方式：synchronized是隐式锁，即通过关键字直接修饰方法或代码块，当线程进入被synchronized修饰的代码块时，会自动获取锁。而ReentrantLock是显式锁，需要手动调用lock()方法获取锁，并且在使用完毕后需要调用unlock()方法释放锁。
2. 锁的灵活性：ReentrantLock提供了更多的高级特性，例如可指定公平性（fairness）和超时（timeout），可以更加灵活地控制锁的行为。ReentrantLock提供了更细粒度的控制。而synchronized则相对简单，不提供这些特性。
3. 性能：在低竞争的情况下，synchronized的性能通常比ReentrantLock好，因为synchronized是JVM层面的内置特性。但在高竞争环境下，ReentrantLock可能更优，因为它提供了更细粒度的控制和高级特性。

### AQS队列为空时线程加入队列发生什么

1. 创建节点：线程会被封装成一个Node节点，并设置相应的线程状态和等待状态。
2. CAS操作：线程会使用CAS（Compare and Swap）操作，尝试**将该节点加入到AQS的同步队列的尾部**。这是一个原子操作，它保证了多个线程同时尝试加入队列时的竞争关系。
3. 加入队列：如果CAS操作成功，即线程成功将节点加入到同步队列的尾部，那么线程将进入**自旋或被阻塞，等待获取锁**。
4. 自旋或阻塞：线程会在自旋或阻塞状态下等待，直到它被唤醒并有机会重新尝试获取锁。自旋是指线程不断地在一个循环内尝试获取锁，而不进行线程的阻塞和切换。如**果自旋不成功或超过一定次数，线程可能会被阻塞**，即进入到操作系统的等待队列中等待唤醒。

### CountDownLatch Semaphore 使用和实现原理 

- CountDownLatch（倒计时门闩） CountDownLatch是一种计数器，它允许**一个或多个线程等待其他线程完成操作后再执行**。主要包含两个方法：countDown()和await()

  - countDown()：每次调用减少计数器的值。当计数器为0时，所有在await()方法上等待的线程会被唤醒继续执行。
  - await()：调用该方法的线程会阻塞，直到计数器为0，才会继续执行。

  使用场景：CountDownLatch通常用于等待一组线程完成某项任务。

  实现原理：CountDownLatch使用了AQS（AbstractQueuedSynchronizer）来进行线程的控制和同步。在CountDownLatch内部有一个**volatile修饰的int类型变量，表示计数器的值**。await()方法会通过自旋和阻塞来等待计数器的值为0，而countDown()方法则会通过CAS操作将计数器的值减1，并唤醒等待的线程。CountDownLatch的实现原理是基于AQS提供的同步工具，利用其中的阻塞和唤醒机制实现线程的等待和通知。

- Semaphore（信号量） Semaphore是一种计数信号量，用于控制同时访问某个资源的线程数量。它可以用来**限制同时访问某个资源的线程数目**，或者用于实现线程间的通信。主要包含两个方法：acquire()和release()。

  - acquire()：尝试获取一个许可，如果没有可用许可，则线程会阻塞等待。
  - release()：释放一个许可，使得其他等待的线程可以继续执行。

  使用场景：Semaphore常用于限制资源的并发访问量，例如数据库连接池、线程池等。

  实现原理：Semaphore的实现原理也是基于AQS。Semaphore内部使用了一个计数器，表示可用的许可数量。acquire()方法会通过自旋和阻塞来等待可用的许可，而release()方法则会通过CAS操作将许可数量加1，并唤醒等待的线程。Semaphore利用AQS提供的同步机制，实现了线程的安全访问和控制。

## JVM

### 有没有遇到过OOM,如何排查

当遇到OOM（Out of Memory）错误时，表示JVM中的内存不足，无法分配更多的对象

- 什么时候会出现OOM问题
  1. 内存泄漏：内存泄漏是指应用程序中的对象占用了内存，但随着时间的推移无法被垃圾回收器释放。
  2. 内存不足：应用程序的内存需求超过了可用的物理内存或JVM的内存限制。
     1. 大量数据处理
     2. 高并发导致程序无法有效地释放已经处理过的对象
     3. 长时间运行导致内存占用累积而触发OOM
- 如何排查OOM
  1. 检查错误日志：首先，查看完整的错误堆栈跟踪和错误信息，了解OOM的具体原因和位置。错误信息通常会提供一些线索来定位问题。
  2. 检查代码逻辑：审查代码，特别是与内存相关的部分，如大数据集合、缓存、文件读写等。确保没有使用过多的内存或存在内存泄漏的情况。另外，还要确保及时释放使用完毕的资源，如数据库连接、文件句柄等。
  3. 检查JVM内存配置：检查JVM的内存配置参数，如最大堆内存（-Xmx）、初始堆内存（-Xms）和永久代大小（如果使用CMS垃圾回收器）。确保这些参数足够大，以适应应用程序的内存需求。
  4. 优化内存使用：根据分析结果，考虑优化内存使用。可能的优化措施包括减少对象的创建、及时释放不再使用的对象、使用缓存技术、调整数据结构大小等。
  5. 使用内存分析工具：使用内存分析工具（如VisualVM、JProfiler、MAT）对应用程序进行实时监测和分析。这些工具可以提供更详细的内存使用情况，帮助识别哪些对象或数据结构占用大量内存，并找出潜在的内存泄漏问题。

### 双亲委派机制的作用（JVM）

双亲委派机制（Parent Delegation Model）是 Java 类加载器的一种工作方式，**用于保证类的唯一性、安全性和隔离性。**

当一个类需要被加载时，首先会由当前类加载器（比如应用程序类加载器）检查自己是否已经加载过这个类。如果已经加载过，则直接返回已加载的类。如果没有加载过，则委托父类加载器（比如扩展类加载器）去加载。父类加载器也会按照同样的逻辑继续向上委派，直到达到最顶层的启动类加载器（Bootstrap ClassLoader）。

如果所有的父类加载器都无法完成加载请求，即找不到所需的类，那么当前类加载器会尝试自己去加载类。如果加载成功，则将类添加到自己的命名空间中，并返回加载的类。如果加载失败，则会抛出 ClassNotFoundException 异常。

### JVM垃圾回收机制

1. 分代回收算法（Generational Collection）：JVM中采用了分代回收的思想。将内存划分为不同的代，如新生代和老年代。新生代通常使用复制算法，因为新生代中的对象生命周期短暂，适合频繁回收。老年代通常使用标记-压缩算法，因为老年代中的对象生命周期较长。
2. 复制算法（Copying）：这是一种适用于新生代的垃圾回收算法。将内存分为两个相等大小的区域，一次只使用其中一个，当一个区域满了后，将存活的对象复制到另一个区域，同时对整个区域进行内存回收。这种算法的特点是高效、简单，但是对于存活对象较多的情况，复制算法的效率会降低。
3. 标记-压缩算法（Mark and Compact）：这是一种适用于老年代的垃圾回收算法。与标记-清除算法类似，先标记出所有可达对象，然后将存活对象压缩到一端，然后清理掉末端的全部内存。这样可以消除内存碎片，提高内存利用率。

## 操作系统与计算机网络

### 进程线程的区别,提示资源分配,空间占用方面

1. 资源占用：每个进程都有独立的内存空间和系统资源，而线程共享进程的资源。
2. 并发性：多个线程可以在同一个进程中并发执行，共享进程的资源。而不同进程之间的并发执行需要通过进程间通信进行数据交换。

### IP地址和MAC地址区别

IP地址是用来标识网络中设备的逻辑地址。用于网络通信。**网络层**

MAC地址是用来标识网络设备的物理地址。MAC地址是设备出厂时就确定的，通常无法更改。**数据链路层**

### Cookie和Session的差别

1. 存储位置：Cookie保存在客户端（浏览器）中，而Session保存在服务器端。
2. 数据的存储方式：Cookie以键值对的形式存储在客户端的浏览器中，而Session则将数据保存在服务器端的内存或者数据库中。
3. 存储容量：Cookie的存储容量有限制，一般为4KB左右。而Session的存储容量相对较大，可以根据服务器的配置进行调整。
4. 生命周期：Cookie可以设置过期时间，可以是会话级的（浏览器关闭后失效）或者持久性的（在一段时间后失效）。而Session的生命周期与用户的会话相关，通常在用户关闭浏览器或者一段时间不活动后失效。
5. 访问方式：Cookie的数据会通过HTTP请求自动发送给服务器，每次请求都会带上Cookie信息。而Session的标识符（通常是一个类似于Session ID的字符串）会在Cookie或者URL参数中传递给服务器。

### HTTP和HTTPs的差别

1. 安全性：HTTP是明文传输协议，数据在传输过程中不加密，容易被窃听和篡改。而HTTPS通过使用SSL/TLS协议对通信内容进行加密，确保数据的机密性和完整性，提供更高的安全性。
2. 默认端口：HTTP默认使用80端口进行通信，而HTTPS默认使用443端口。
3. 证书：为了建立HTTPS连接，服务器需要获得一个有效的数字证书，由权威的证书颁发机构（CA）签发。这个证书用于验证服务器身份并确保通信的安全性。而HTTP不需要证书验证。

### http状态码，https怎么建立连接的

- HTTP状态码
  1. 2XX：成功状态码 （200 OK）
  2. 3XX：重定向状态码
  3. 4XX：客户端错误状态码 （400 Bad Reque、403 Forbidden、404 NotFound）
- https怎么建立连接的
  1. **客户端发起连接**：客户端向服务器发送HTTPS请求时，会将其通信协议指定为HTTPS，即使用默认的443端口。
  2. **服务器配置SSL/TLS证书**：服务器需要配置有效的SSL/TLS证书，并将其与特定的域名关联。证书通常由可信任的第三方机构（如CA认证机构）签发，用于证明服务器的身份。
  3. **发送服务器证书**：服务器在响应客户端请求时，会将自己的SSL/TLS证书发送给客户端。这个证书包含了服务器的公钥以及其相关信息（如证书颁发机构等）。
  4. **验证服务器证书**：客户端收到服务器证书后，会验证其合法性和真实性。验证包括检查证书的签名是否有效、证书是否过期等。如果验证失败，客户端会发出警告或终止连接。
  5. **协商加密算法**：客户端选择与服务器进行安全通信所使用的加密算法和密钥长度。通常，客户端会提供一组支持的加密算法供服务器选择。
  6. **生成密钥**：客户端和服务器都会生成用于加密通信的会话密钥（对称密钥），这个密钥只在当前会话中使用，提供会话级别的安全性。
  7. **使用服务器公钥加密**：客户端使用服务器的公钥对会话密钥进行加密，并将其发送给服务器。
  8. **使用私钥解密**：服务器接收到加密的会话密钥后，使用自己的私钥进行解密，得到对称密钥。
  9. **安全通信**：在随后的HTTPS通信过程中，客户端和服务器使用对称密钥来加密和解密传输的数据，以确保数据的保密性和完整性。

### tcp和udp区别，udp用在哪些地方

- tcp和udp区别
  1. 连接性：TCP是面向连接的协议，而**UDP是无连接的协议**。TCP通过在通信双方之间建立可靠的连接来传输数据，而UDP则没有连接的概念，每个数据包都独立发送。
  2. 可靠性：TCP提供可靠的数据传输，使用数据确认、序列号和重传机制来确保数据的正确性和完整性。UDP不提供这些特性，因此对数据传输的可靠性没有严格要求。
  3. 速度和效率：由于TCP提供的可靠性和保证数据顺序到达的机制，它会引入一定的延迟，并可能消耗更多的网络资源。相比之下，UDP没有这些机制，因此传输速度更快，效率更高。
  4. 数据包顺序：**TCP保证数据包按发送顺序到达目标设备**，不会出现乱序的情况。而UDP不提供这个保证，数据包可能以任意顺序到达。
- UDP用在哪些地方
  1. 实时应用：UDP适合用于实时应用，如音频和视频流传输，因为在这些应用中，即使丢失一些数据包，也不会对整体体验产生重大影响。例如，语音通话、视频会议和直播等。
  2. 广播和多播：UDP支持广播和多播，可以将数据同时发送给多个接收者。这在流媒体服务、在线游戏和网络广播等场景中经常使用。
  3. DNS解析：域名系统（DNS）使用UDP进行域名解析，因为在通信过程中，需要快速地查询和获取数据，而不需要确保数据的完整性。

## Spring框架

### 你最擅长的Java框架,介绍一下 Spring的核心思想

Spring框架的核心思想是**IOC**（Inversion of Control，控制反转）和**AOP**（Aspect-Oriented Programming，面向切面编程）。

1. IOC（控制反转）：IOC的核心理念是将对象的创建、依赖注入和生命周期管理交给Spring容器来完成，通过配置文件或注解的方式，让Spring容器在运行时动态地管理和组装对象。能够降低代码的耦合性、提高代码的可维护性和可测试性。
2. AOP（面向切面编程）：AOP通过在不修改原有代码的情况下，增加一些额外的功能和行为。例如，日志记录、事务管理等功能可以横切于多个对象和方法。在Spring中，AOP通过**代理模式**实现，通过配置文件或注解的方式，将这些横切关注点与核心业务逻辑进行解耦，使得系统的设计更加清晰，并且能够重用这些横切关注点。

### 什么是动态代理 什么是CGI

- 动态代理 基于接口的代理

  JDK 动态代理主要涉及到 `java.lang.reflect` 包中的两个类：`Proxy` 和 `InvocationHandler`。 `InvocationHandler`是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类 的代码，**动态将横切逻辑和业务逻辑编制在一起**。`Proxy` 利用 `InvocationHandler` 动态创建 一个符合某一接口的实例，生成目标类的代理对象动态代理拼接

- CGLIB（字节码生成库）基于类的代理

  CGLIB 会生成目标对象的子类，并重写目标对象的方法来实现代理逻辑。

### Spring Bean 生命周期

1. 实例化（Instantiation）：在这个阶段，Spring会**根据配置文件或注解创建Bean的实例**。实例化可以通过无参数构造函数、工厂方法或者特定的实例化策略来完成。
2. 属性赋值（Population of Properties）：在实例化之后，Spring会使用**依赖注入**（Dependency Injection）机制将配置的**属性值设置**到Bean实例中。这可以通过XML配置文件、注解或者Java配置来完成。
3. 初始化（Initialization）：在属性赋值完成之后，Spring会调用**初始化回调方法**，以便Bean可以执行一些初始化的操作。常见的初始化回调方法有InitializingBean接口的afterPropertiesSet()方法和@PostConstruct注解标记的方法。
4. 使用中（In Use）：**Bean在Spring缓存中**。在初始化完成后，Bean就可以被应用程序使用了。此时，Bean可以响应业务逻辑中的方法调用和其他操作。
5. 销毁（Destruction）：当应用程序关闭或Bean不再需要时，Spring会**调用销毁回调方法**，以便Bean执行一些清理操作。常见的销毁回调方法有DisposableBean接口的destroy()方法和@PreDestroy注解标记的方法。

### 讲讲一个http请求发到controller的过程

1. 客户端发送请求：客户端通过 HTTP 协议向服务器发送请求，包括请求的 URL、请求方法（GET、POST 等）、请求头、请求体等信息。
2. **DispatcherServlet** 拦截请求：Spring Boot 的核心组件 DispatcherServlet 拦截到客户端发送的请求。DispatcherServlet 是一个前置控制器，负责处理所有的请求分发和委派。
3. **HandlerMapping** 查找处理器：DispatcherServlet 调用 HandlerMapping 来查找适合处理当前请求的处理器（即 Controller）。HandlerMapping 根据请求的 URL、请求方法等信息来确定对应的处理器。
4. **HandlerAdapter** 执行处理器：一旦找到了匹配的处理器，DispatcherServlet 就会调用 HandlerAdapter 来执行该处理器。HandlerAdapter 是适配器模式的实现，它能够使得不同类型的处理器能够统一执行。
5. 执行业务逻辑：**Controller** 接收到请求后，根据业务逻辑进行处理。它会处理请求参数、调用 Service 层或其他相关组件进行业务处理，并返回处理结果。
6. 处理响应：Controller 处理完成后，会将处理结果封装成一个 ModelAndView 对象（包含响应的数据和视图信息），然后返回给 DispatcherServlet。

### DispatcherServlet是干嘛的

DispatcherServlet充当了前端控制器（Front Controller）的角色，负责协调和管理Spring MVC框架中的各个组件，实现了请求的统一入口和全局的请求处理逻辑

1. 请求分发：当客户端发送一个HTTP请求时，DispatcherServlet接收到该请求并根据配置的URL映射规则，将请求转发给对应的控制器（Handler）进行处理。
2. 视图解析：在控制器方法处理完请求后，DispatcherServlet会根据配置的视图解析器（View Resolver）将处理结果转化为具体的视图对象（如JSP页面、Thymeleaf模板等）。
3. 异常处理：DispatcherServlet还负责处理请求过程中可能产生的异常，并通过配置的异常处理器（Exception Resolver）来选择合适的方式进行异常处理，如返回错误页面或JSON格式的错误信息。

### Spring怎么解决循环依赖问题

Spring中两个或多个 Bean 互相之间持有对方的引用就会发生循 环依赖。循环的依赖将会导致注入死循环。

1. 当Spring创建一个Bean时，首先检查singletonObjects（一级缓存）缓存中是否存在该Bean的实例。如果存在，直接返回实例。如果不存在，则继续下一步。
2. Spring将正在创建的Bean对象存放在早期暴露的对象缓存earlySingletonObjects（二级缓存）中，但此时只是占位符（early-stage object）。
3. 接下来，Spring继续创建Bean的过程，如果发现循环依赖，即A依赖B，B又依赖A，那么Spring将返回earlySingletonObjects缓存中的占位符。
4. 此时，Spring开始解决循环依赖，通过调用构造函数或者setter方法，将所需的依赖注入到占位符中。
5. 当依赖注入完成后，Spring将真正创建好的Bean对象放置到singletonObjects缓存中。这时，其他需要此Bean的组件就可以通过singletonObjects缓存获取到该Bean的实例。
6. 最后，Spring根据循环依赖链的深度进行逐级清理，将earlySingletonObjects缓存中的占位符替换为真正的Bean对象。

### Spring中使用多线程

SpringBoot应用中需要添加`@EnableAsync`注解，来开启异步调用，一般还会配置一个线程池，异步的方法交给特定的线程池完成。

**获取异步方法返回值**

当异步方法有返回值时，如何获取异步方法执行的返回结果呢？这时需要异步调用的方法带有返回值CompletableFuture。

CompletableFuture是对Feature的增强，Feature只能处理简单的异步任务，而CompletableFuture可以将多个异步任务进行复杂的组合。

**注意事项**

`@Async`注解会在以下几个场景失效，也就是说明明使用了`@Async`注解，但就没有走多线程。

- 异步方法使用static关键词修饰；
- 异步类不是一个Spring容器的bean（一般使用注解`@Component`和`@Service`，并且能被Spring扫描到）；
- SpringBoot应用中没有添加`@EnableAsync`注解；
- 在同一个类中，一个方法调用另外一个有@Async注解的方法，注解不会生效。原因是@Async注解的方法，是在代理类中执行的。

需要注意的是： 异步方法使用注解@Async的返回值只能为void或者Future及其子类，当返回结果为其他类型时，方法还是会异步执行，但是返回值都是null

### 登录系统的Cookie和Session如何设计？

1. 用户登录：用户通过提供用户名和密码进行登录，服务器验证用户凭据，如果通过验证，则生成一个唯一的 Session ID，并将该 ID 保存到服务器端。
2. Cookie 的设置：在服务器返回响应给客户端时，将 Session ID 添加到 Cookie 中，并设置 Cookie 的有效期。将 Cookie 发送给客户端保存。
3. 客户端请求：客户端在后续的请求中会自动将 Cookie 带上，发送给服务器。
4. 服务器验证：服务器接收到请求时，会从 Cookie 中获取 Session ID，并与服务器端存储的 Session ID 进行比较。
5. Session 管理：服务器端维护一个 Session 数据库或者缓存，用于存储每个 Session ID 对应的用户信息和其他需要保存的数据。（可以用Redis存储）

### Spring的@Transaction，假如我一个@Service，里面有两个public方法A和B，A上面没有@Transaction，B有，A方法调用B方法，事务会生效吗？

不会

当一个类被标记为 @Service 时，Spring会为该类创建一个**代理对象**。这个代理对象会拦截所有对该类的方法调用，并在方法执行前后进行一些额外的处理，如开启和提交事务。但是这个代理对象**只能拦截从外部类调用的方法**，而无法拦截类内部方法之间的相互调用。

- 怎么使事务生效
  1. 可以通过将方法B提取到另一个类中，并通过在类上添加 @Transactional 注解，确保代理机制能够拦截方法B的调用
  2. 或者在方法A上也添加 @Transactional 注解，确保方法A和B都处于同一个事务的管理下。

### MyBatis的缓存机制，有哪些缓存策略

- 缓存机制

  1. 一级缓存（Local Cache）：
     - **默认开启**，是在**同一个 SqlSession 内部**的缓存。
     - 作用范围是 Session 级别，同一个 Session 内部的多次查询可以复用缓存。
     - 一级缓存是基于对象引用来实现的，当数据发生变化时，缓存会失效。
  2. 二级缓存（Second Level Cache）：
     - 可以配置全局的缓存，作用范围是**多个 SqlSession 之间**的缓存。
     - 默认不开启，需要手动进行配置和启用。
     - 对于经常被查询的数据，可以放到二级缓存中，在多个 SqlSession 之间共享缓存。
     - 二级缓存是基于序列化来实现的，数据变化时需要更新缓存。

- 缓存策略

  MyBatis 提供了多种缓存策略，例如 LRU（最近最少使用）、FIFO（先进先出）、SOFT（软引用）和WEAK（弱引用）等

### 如果没有Spring怎么开发

1. 选择其他框架：Java EE
2. 数据库操作：
   - 使用 JDBC：Java Database Connectivity（JDBC）是 Java 提供的标准数据库连接接口，可以直接使用 JDBC 进行数据库操作。
   - 使用 ORM 框架：选择其他 ORM（对象关系映射）框架，如 Hibernate、MyBatis 等，它们可以简化数据库访问和操作。
3. Web 开发：
   - 使用 Servlet 和 JSP：Java 的标准技术，可以进行 Web 开发。使用 Servlet 处理请求和生成响应，使用 JSP 进行页面展示和动态内容生成。
4. 依赖注入：
   - 手动依赖管理
   - 使用其他轻量级的依赖注入框架：选择其他的依赖注入框架，如 Google Guice、PicoContainer 等，它们提供类似于 Spring 的依赖注入功能。
5. AOP（面向切面编程）：
   - 使用其他 AOP 框架：如 AspectJ 等。

## MySQL数据库

### 事务特性

原子性（Atomicity）
• 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

一致性（Consistency）
• 事务开始前和结束后，数据库的完整性约束没有被破坏。比如A向B转账，不可能A扣了钱，B却没收到。

隔离性（Isolation）
• 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。
 
持久性（Durability）
• 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。

### 数据库的事务,并发事务会带来哪些问题,MySQL的默认隔离级别 如何在数据库中实现数据的备份和恢复

- 并发事务会带来哪些问题
  1. 数据不一致：并发事务可能导致数据的不一致性。当多个事务同时读取和修改同一份数据时，如果没有适当的并发控制机制，就有可能导致数据的错乱和不一致。
  2. 丢失更新：并发事务中的更新操作可能会相互覆盖，从而导致部分更新的丢失。例如，两个事务同时读取一个数据并进行修改，然后将结果写回数据库，如果没有适当的并发控制机制，其中一个事务的修改结果可能会被另一个事务的覆盖，导致数据的丢失。
  3. 脏读（Dirty Read）：脏读是指一个事务在读取了另一个事务未提交的数据之后，又进行了一次读取操作，此时可能读取到的数据是不正确或无效的。这种情况下，事务可能基于不一致或临时的数据进行后续操作，导致数据的错误处理和错误结果。
  4. 不可重复读（Non-repeatable Read）：不可重复读是指一个事务在读取了某个数据后，又进行一次读取操作，但此时读取到的数据已经发生了改变。这种情况下，事务可能会在两次读取之间对数据进行了一些操作（如修改或删除），导致前后两次读取的数据不一致。
  5. 幻读（Phantom Read）：幻读是指一个事务在同样的查询条件下，由于其他并发事务的插入或删除操作，导致前后两次查询的结果集不一致。这种情况下，事务在处理某个数据集时，可能会发现新增或删除了一些记录，导致数据的不完整性。
- 解决并发事务带来的问题
  1. 锁定机制
  2. 隔离级别
  3. 事务调度算法
- MySQL隔离级别
  1. 读未提交（Read Uncommitted）：最低的隔离级别，事务可以读取其他事务尚未提交的数据。这可能导致脏读、不可重复读和幻读的问题。
  2. 读已提交（Read Committed）：事务只能读取其他事务已经提交的数据。这解决了脏读的问题，但仍可能存在不可重复读和幻读的问题。
  3. 可重复读（Repeatable Read）：**MySQL 默认的隔离级别**。事务在启动时创建一个一致性视图，保证在整个事务期间读取的数据不受其他事务的影响，解决了不可重复读的问题。但仍可能存在幻读的问题。
  4. 串行化（Serializable）：最高的隔离级别，通过强制事务的串行执行来避免并发问题。事务会在读取和修改数据时对数据进行锁定，确保其他事务无法同时修改被锁定的数据。这可以解决脏读、不可重复读和幻读的问题，但可能降低并发性能。

### MySQL数据库的索引结构为什么用b+树，b树缺点？

- b树和b+树
  - B树：
    - 节点既存储数据也存储关键字。
    - 内部节点和叶子节点的结构相同。
    - 拥有更高的填充度，节点利用率较高。
    - 适用于随机访问和插入操作。
  - B+树：
    - 内部节点只存储关键字。
    - 叶子节点存储所有数据，并通过指针连接形成有序链表。
    - 内部节点能容纳更多的子节点指针。
    - 适用于顺序访问和范围查询。
    - 在数据库索引中使用较为广泛。
- MySQL数据库的索引结构为什么用b+树，b树的缺点
  1. B树的内部节点存储数据：B树的每个节点都会存储关键字和对应的数据，这意味着一个节点的大小是相对较大的。当B树的高度比较大时，磁盘IO操作会变得频繁，因为每次读取一个节点时需要读取更多的数据，而不仅仅是所需的关键字。
  2. B树的查询效率相对较低：由于B树的节点即存储关键字又存储数据，因此在查找某个关键字时，可能需要在每个节点中进行比较操作，这会增加查询的时间复杂度。尤其是在高度较高的B树中，查询性能会进一步降低。
  3. B+树的查询效率更高：B+树在进行关键字查找时，只需要在内部节点中进行比较操作，然后通过叶子节点指针快速定位到对应的数据节点，减少了比较的次数，提高了查询效率。
  4. B+树的范围查询效率更高：由于B+树的叶子节点通过指针连接成有序链表，范围查询只需要遍历叶子节点链表即可，不需要在内部节点中进行遍历，大大提高了范围查询的效率。

### MySQL行数多了为什么会变慢 加索引为什么会快

- MySQL行数多了为什么会变慢

  1. 磁盘IO：随着行数的增加，磁盘IO操作可能会变得更频繁。当数据无法完全加载到内存中时，MySQL需要从硬盘读取数据，而硬盘读取速度相对较慢，会导致查询速度下降。
  2. 索引失效：如果数据库表没有适当的索引或索引选择不当，随着行数的增加，MySQL可能需要进行全表扫描来找到匹配的数据。全表扫描需要遍历每一行数据，耗时较长，导致查询性能下降。
  3. 锁竞争：当多个并发事务同时查询或修改同一个表时，随着行数的增加，锁竞争的概率也增大。如果锁竞争过于激烈，可能导致查询被阻塞，从而影响查询性能。

- 加索引为什么会快

  

### 怎么设计数据库索引

1. **使用频率高得列作为索引**：索引应该选择在经常使用的查询条件
2. **考虑列的选择性**：选择性是指索引列中不同值的数量与总行数的比例。即大部分行都有不同的值，建立索引会更有优势。
3. **注意索引列的大小**：索引列的大小应尽可能小，这样可以减少索引占用的存储空间，并提高索引查询的效率。一般来说，整数类型比字符类型更适合作为索引列。
4. **考虑多列索引**（复合索引）：当多个列组合在一起用于查询时，可以考虑创建复合索引。复合索引可以提高多个列组合查询的效率，并且在某些情况下比单列索引更有效。
5. **避免过多的索引**：过多的索引会增加维护成本，并且可能导致性能下降。只创建必要的索引，避免创建过多冗余的索引。
6. **定期更新和重新组织索引**：随着数据的插入、更新和删除，索引可能会变得不均衡或不连续。定期对索引进行更新和重新组织可以保持索引的效率。

### 最左匹配原则是什么，以及为什么这样就可以用到联合索引

- “最左匹配原则”是指在联合索引中，如果查询条件涉及到联合索引的多个列，那么查询时只能使用联合索引的最左边的列开始匹配。也就是说，对于一个联合索引 (A, B, C)，如果查询条件只涉及到 A 和 B，而不包括 C，那么这个联合索引可以被用到；但是如果查询条件只涉及到 B 和 C，而不包括 A，那么这个联合索引将无法被用到。
- 这是因为**联合索引的数据结构是按照索引的列顺序进行排序和存储的**。当查询时，数据库引擎会根据最左匹配原则来定位索引中的数据。如果查询条件只涉及到联合索引的最左边的列，数据库可以直接使用索引定位到对应的数据行，从而提高查询效率。

###  联合索引为什么要遵守前缀匹配？

当使用联合索引进行查询时，如果查询条件只涉及到索引的前缀列，即根据索引的最左边的几列进行匹配，那么数据库可以直接利用索引定位到符合条件的数据行，从而大大减少了扫描的数据量

举个例子，假设有一个联合索引 (A, B, C)，我们有以下两种查询条件：

1. 查询条件为 A = 1：这个查询可以利用索引的最左前缀 A 进行匹配，即可以快速定位到符合条件的数据行。
2. 查询条件为 B = 2：这个查询无法利用索引进行快速定位，需要扫描索引中所有 B 列等于 2 的数据行，效率相对较低。

### MySQL有哪些日志，分别起什么作用

1. 二进制日志（Binary Log）：
   - 作用：记录对数据库的修改操作，包括增删改表数据的语句。
   - 使用场景：用于数据恢复、数据复制和主从同步。
2. 错误日志（Error Log）：
   - 作用：记录 MySQL 服务器运行过程中出现的错误和异常信息。
   - 使用场景：用于故障排查和问题分析。
3. 查询日志（General Query Log）：
   - 作用：记录所有进入 MySQL 服务器的查询语句，包括 SELECT、INSERT、UPDATE、DELETE 等。
   - 使用场景：用于排查慢查询和审计查询的使用情况。
4. 慢查询日志（Slow Query Log）：
   - 作用：记录执行时间超过阈值的查询语句，通常用于优化和改进查询性能。
   - 使用场景：用于定位和优化数据库中的慢查询语句。
5. 事务日志（Transaction Log）或重做日志（Redo Log）：
   - 作用：记录已提交事务的修改，以确保数据持久性和一致性。
   - 使用场景：用于崩溃恢复和故障恢复，保证数据的完整性。
6. 撤销日志（Undo Log）：
   - 作用：记录事务中对数据的修改，在事务回滚或 MVCC（多版本并发控制）时使用。
   - 使用场景：用于撤销已提交事务的修改或提供读一致性视图。

### MySQL MVCC  原理

MVCC（Multi-Version Concurrency Control）是一种并发控制机制

1. 版本号：每个数据行在插入或更新时都会有一个版本号，在InnoDB中使用6字节的数字表示。这个版本号是基于事务ID（Transaction ID）来分配的。
2. Undo日志：InnoDB使用Undo日志来记录对数据行的修改，通过回滚这些Undo日志可以撤销已提交的事务对数据行的修改。Undo日志存储了旧版本的数据值，用于回滚操作和读取已提交的旧版本数据。
3. Read View（读视图）：每个事务在开始时会创建一个Read View，用于确定事务可见的数据行版本。Read View包含事务启动时系统中有效的活跃事务列表和已提交事务列表。事务只能看到已提交事务开始之前的版本。
4. Consistent Read（一致性读）：对于一致性读操作（例如SELECT），InnoDB会根据事务的Read View找到符合条件的最新版本数据行。如果某个数据行的版本在事务的Read View之后，那么这个数据行对于该事务来说是不可见的。
5. Read Committed隔离级别：InnoDB的默认隔离级别是Read Committed，它保证每个查询都使用当前的Read View来获取数据，从而提供了一致性的读取。
6. 快照读（Snapshot Read）：当事务执行SELECT语句时，它会使用当前的Read View来确定可见的数据行版本。这个操作称为快照读，它允许在事务执行期间保持数据的一致性状态。
7. 间隙锁（Gap Lock）：MVCC机制在一定程度上避免了写操作之间的冲突，但可能存在幻读问题（即在一个事务中两次执行相同查询，第二次查询会返回额外的行）。为了解决幻读问题，InnoDB引入了间隙锁，用于防止其他事务在范围内插入新记录。

### MySQL索引类型，什么是聚簇索引，什么是非聚簇索引

1. 聚簇索引（Clustered Index）： 聚簇索引是一种特殊的索引类型，它决定了数据在磁盘上的物理存储顺序。每个表只能有一个聚簇索引。聚簇索引的叶子节点存储了实际的数据行，而非叶子节点存储了索引键值及指向下一级节点的指针。聚簇索引对于频繁基于范围查询和排序的操作非常有效。
2. 非聚簇索引（Non-clustered Index）： 非聚簇索引是另一种常见的索引类型。与聚簇索引不同，非聚簇索引的叶子节点并不存储实际的数据行，而是存储了索引键及指向对应数据行的指针。因此，通过非聚簇索引可以快速定位到满足查询条件的数据行，然后再使用指针获取相应的数据。

### MySQL的WAL原则

WAL（Write-Ahead Logging）是一种数据库事务日志机制，用于确保事务的持久性和恢复能力。

MySQL使用了两个关键的日志文件，即重做日志（Redo Log）和回滚日志（Undo Log）。

1. 重做日志（Redo Log）：在WAL原则中，重做日志用于记录在事务提交之前对数据所做的修改操作。在事务提交之前，相关的修改操作首先被写入重做日志中，然后才将其应用到数据库中。这样即使在系统发生故障或崩溃时，MySQL也可以使用重做日志来恢复数据，并确保数据的一致性和完整性。
2. 回滚日志（Undo Log）：回滚日志记录了事务所做的修改操作的反向操作，也就是撤销操作。

#### Redis的AOF遵守WAL原则吗

Redis的AOF（Append-Only File）持久化机制可以说是部分地遵守WAL（Write-Ahead Logging）原则。

在AOF持久化模式下，Redis将所有写操作追加到AOF文件的末尾，而不是像传统的数据库系统一样先写日志文件再修改内存数据。这意味着 Redis 的 AOF 日志记录的是最终状态，而不是每个独立的操作。

### MySQL怎么排查慢查询

查询慢查询日志，分析导致慢查询的语句

可以使用`EXPLAIN`关键字来了解MySQL优化器的查询执行计划。通过执行`EXPLAIN`加上需要分析的SQL语句，可以获取到查询计划的详细信息，包括索引使用情况、表扫描方式等。

### MySQL支持事务的存储引擎

MySQL支持多种存储引擎，其中一些支持事务的存储引擎包括：

1. InnoDB：InnoDB是MySQL的默认存储引擎，也是最常用的支持事务的引擎。它提供了ACID（原子性、一致性、隔离性和持久性）特性，并支持行级锁定，具有较好的并发性能和数据完整性。
2. NDB Cluster：NDB Cluster（也称为MySQL Cluster）是为分布式环境设计的高可用性存储引擎。它使用多个节点共同存储和处理数据，提供了实时复制和故障恢复功能，支持事务和并发性。
3. MyRocks：MyRocks是一个基于RocksDB引擎的存储引擎，它使用了写优化和压缩算法来提供高效的存储和查询性能。MyRocks在MySQL 5.6版本之后成为可用的存储引擎，并且支持事务。

### SQL语句的执行顺序

在 SQL 语句中，通常是先执行远离 WHERE 语句的部分，然后再执行 WHERE 语句。具体执行顺序如下：

1. FROM 子句中指定的表：SQL 语句首先从 FROM 子句中指定的表开始执行。这一步涉及从表中获取相关的数据。
2. JOIN 子句（如果有的话）：如果 SQL 语句包含 JOIN 子句，那么表之间的连接会在获取数据之前进行计算。这一步将数据从多个表连接起来。
3. WHERE 子句：一旦表和连接准备好，WHERE 子句中的条件将被应用于结果集。这一步筛选出满足条件的数据行。
4. GROUP BY 子句（如果有的话）：如果 SQL 语句包含 GROUP BY 子句，那么数据将按照 GROUP BY 子句中的列进行分组。
5. HAVING 子句（如果有的话）：HAVING 子句用于筛选 GROUP BY 后的结果集。它与 WHERE 子句不同，WHERE 子句在 GROUP BY 之前应用，而 HAVING 子句在 GROUP BY 之后应用。
6. SELECT 子句：SELECT 子句用于选择需要返回的列，并可以对数据进行计算、排序等操作。这一步执行的是选择和处理列的操作。
7. ORDER BY 子句（如果有的话）：如果 SQL 语句包含 ORDER BY 子句，那么数据将按照 ORDER BY 子句指定的列进行排序。
8. LIMIT 子句（如果有的话）：LIMIT 子句用于限制结果集的数量



## Redis 缓存

### Redis 为什么快，为什么能处理高并发？

1. Redis 完全基于**内存**，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于 HashMap, HashMap 的优势就是查找和操作的时间复杂度是O(1)；

2. **数据结构简单**，对数据的操作也简单；

3. 采用**单线程**，Redis 的命令都是原子操作，避免了不必要的上下文切换和竞争条件，不存在多线程导致的CPU切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗；

4. 使用**多路复用 IO **模型，非阻塞 IO：传统的并发模型：每个 I/O 流都有一个新的线程管理；

   I/O多路复用：只有单个线程，通过追踪每个 I/O 流的状态，来管理多个 I/O 流；

5. 使用的底层模型不同，它们之间底层实现方法以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制，因为一般的系统调用系统函数的时候，会浪费一定的事件去移动和请求。

### Redis 为什么采用单线程 

对于一个 DB 来说，**CPU 通常不会是瓶颈**，因为大多数请求不会是 CPU 密集型的，而是
IO 密集型。具体到 Redis的话，如果不考虑 RDB/AOF 等持久化方案，Redis 是完全的纯内存操作，执行速度是非常快的，因此这部分操作通常不会是性能瓶颈，**Redis 真正的性能瓶颈在于网络 I/O**，也就是客户端和服务端之间的网络传输延迟，因此 Redis选择了单线程的 I/O 多路复用来实现它的核心网络模型。

1.Redisv4.0(引入多线程处理异步任务)
2.Redis 6.0(在网络模型中实现多线程 I/O )
所以，网络上说的Redis是单线程，通常是指在Redis 6.0之前，其核心网络模型使用的是单线程。
目Redis6.0引入多线程I/O，只是用来处理网络数据的读写和协议的解析，而执行命令依旧是单线程。

### Redis 基本类型

1. 字符串（String）：用于存储单个值，可以是字符串、整数或浮点数。
2. 哈希（Hash）：用于存储字段和值的映射关系，类似于关联数组或字典。适合存储对象。
3. 列表（List）：按照插入顺序存储的字符串元素列表。可以在列表头部或尾部插入、删除元素，还可以根据索引获取范围内的元素。
4. 集合（Set）：无序的字符串集合，不允许重复的元素。可以对集合执行添加、删除、查找等操作。
5. 有序集合（Sorted Set）：与集合类似，每个元素都会关联一个分数，根据该分数进行排序。可以根据分数范围获取元素，也可以根据排名获取元素。
6. 位图（Bitmap）：位图是由二进制位组成的数据结构，可以表示一系列的开关状态或标记。

### Redis 持久化方式

Redis为了保证效率，数据存储在了内存中，但是会周期性地把更新的数据写入磁盘或者把修改操作写成追加的记录文件中，以保证数据的持久化。

- Redis的持久化策略有两种：
  - RDB(Redis database)：直接把内存中的数据保存到一个dump的文件中，定时保存；
  - AOF(Append Only File)：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。
  - Redis默认是快照RDB的持久化方式。当Redis重启的时候，它会优先使用AOF文件来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。
- RDB和AOF的区别
  1. RDB是一次全量备份，AOF日志是连续的增量备份；
  2. RDB是内存数据的二进制序列化形式，在存储上非常紧凑，而AOF日志记录的是内存数据修改的指令记录文本；
- 如何选择合适的持久化方式
  1. 如果是数据比较重要，不想再从其他地方获取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用RDB。
  2. 如果是用做内存数据库，建议是RDB和AOF都开启，或者定期执行bgsave做快照备份，RDB方式更适合做数据的备份，AOF可以保证数据的不丢失。
  3. Redis 4.0 更新了混合了 RDB 和 AOF 格式的增量数据

### Redis 的扩容方式

- 如果 Redis 被当作缓存使用，使用**一致性哈希实现动态扩容缩容**。
- 如果 Redis 被当做一个持久化存储使用，必须使用**固定的 keys-to-nodes 映射**关系，节点的数量一旦确定不能变化。否则的话，必须使用可以在运行时进行数据再平衡的一套系统，而当前只有 Redis 集群可以做到这样。

### Redis 过期键的删除策略

Redis 的过期删除策略就是: **惰性删除**和**定期删除**两种策略配合使用。

- 惰性删除: 惰性删除不会去主动删除数据，而是在**访问数据的时候，再检查**当前键值是否过期，如果过期则执行删除并返回 null 给客户端，如果没有过期则返回正常信息给客户端。它的优点是简单，不需要对过期的数据做额外的处理，只有在每次访问的时候才会检查键值是否过期，缺点是删除过期键不及时，造成了一定的空间浪费。
- 定期删除: Redis 会**周期性的随机测试**一批设置了过期时间的 key 并进行处理。测试到的已过期的 key 将被删除。

### Redis 的缓存淘汰策略

**常用策略**

1. FIFO（First In, First Out）：先进先出策略，即淘汰最早添加的缓存数据。
2. LRU（Least Recently Used）：最近最少使用策略，即淘汰最久未被使用的缓存数据。
3. LFU（Least Frequently Used）：最不经常使用策略，即淘汰使用频率最低的缓存数据。
4. Random（随机策略）：随机选择要淘汰的缓存数据。

**Redis 内置策略**

- volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。
- volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。
- volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。
- volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰。
- allkeys-lru：从数据集中挑选最近最少使用的数据淘汰
- allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰。
- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
- no-enviction（驱逐）：禁止驱逐数据，这也是默认策略。意思是当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用no-enviction策略可以保证数据不被丢失。


### 为何 Redis 使用跳表而非红黑树实现 SortedSet （zset）？

Redis中的有序集合支持的核心操作主要支持：

- 插入一个数据
- 删除一个数据
- 查找一个数据
- 迭代输出有序序列
  以上操作，红黑树也能完成，时间复杂度跟跳表一样O(log n)。
- 按照区间查找数据
  红黑树的效率低于跳表。跳表可以做到O(logn)定位区间的起点，然后在原始链表顺序往后遍历即可。

### 布隆过滤器原理

布隆过滤器（Bloom Filter）是一种空间效率非常高的概率型数据结构，用于判断一个元素是否存在于一个集合中。

1. 初始化：创建一个位数组（bit array），长度为 m，并将所有位初始化为 0。
2. 添加元素：当要向布隆过滤器中添加一个元素时，使用多个独立的哈希函数将该元素映射到位数组的不同位置，并将对应位置的位设为 1。
3. 检查元素：当要检查一个元素是否存在于布隆过滤器中时，使用相同的哈希函数计算该元素对应的位数组位置，并检查对应位置的位值。如果其中有任何一位为 0，则可以确定该元素一定不存在于布隆过滤器中；如果所有位都为 1，则表示该元素可能存在于布隆过滤器中。

因为多个元素可能映射到位数组上相同的位，从而导致某些元素的存在被错误地判断为存在。误判率取决于位数组的大小、哈希函数的数量和哈希函数的质量。因为多个元素可能映射到位数组上相同的位，从而导致某些元素的存在被错误地判断为存在。误判率取决于位数组的大小、哈希函数的数量和哈希函数的质量。

### 缓存与数据库一致性问题

1. 先更新数据库，再更新缓存
2. 先更新缓存，再更新数据库
3. 先删除缓存，后更新数据库
4. 先更新数据库，后删除缓存

第一种和第二种方案，没有人使用的，因为第一种方案存在问题是: 并发更新数据库场景下，会将**脏数据**读到缓存。

第二种方案存在的问题是: 如果先更新缓存成功，但是数据库更新失败，则肯定会造成**数据不一致**。

目前主要用第三和第四种方案

第三种方案也存在问题

该方案也会出问题，此时来了两个请求，请求 A(更新操作) 和请求 B(查询操作)

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

### 解决缓存与数据库一致性问题

- 延时双删（针对先删缓存后更新数据）

  (1) 先淘汰缓存
  (2) 再写数据库《这两步和原来一样)
  (3) 休眠1秒，再次淘汰缓存，这么做，可以将1秒内所造成的缓存脏数据，再次删除。确保读请求结束，写请求可以删除读请求造成的缓存脏数据。

- 消息队列发送缓存删除补偿

  Redis 删除时报错，通过消息队列通知系统，系统接受到消息后再次删除

### 什么是缓存穿透 怎么解决

缓存穿透是指用户请求的数据在缓存中不存在即**没有命中**，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致**短时间大量请求落在数据库上，造成数据库压力过**大，甚至导致数据库承受不住而宕机崩溃。

- 方法1：将无效的 key 存入 Redis 中
- 方法2：布隆过滤器，在查询 Redis 前先去布隆过滤器查询 key 是否存在

### 什么是缓存雪崩 怎么解决

如果缓存在某一个时刻出现大规模的 key 失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。

主要有两种可能: 第一种是Redis宕机，第二种可能就是采用了相同的过期时间。

- 方法
  1. 事前
     - 均匀过期：设置不同的过期时间
     - 分级缓存：多级缓存，每层缓存失效时间不同
     - 热点数据永不过期
     - Redis 集群避免全盘崩溃
  2. 事中
     - 互斥锁：缓存失效后，控制互斥锁或者消息队列来控制读写缓存的线程数量
     - 熔断机制：流量达到阈值直接返回系统拥挤
  3. 事后
     - 通过 Redis 持久化机制，尽快恢复缓存

### Redis的Set元素过多怎么办

1. **分页查询**：通过使用 Redis 的分页查询功能，将 Set 元素按照一定的数量进行分页处理。可以使用命令如 `ZRANGE` 或 `ZREVRANGE` 来获取指定范围内的元素，然后再根据需要进行展示或处理。
2. **使用有序集合**（Sorted Set）：如果对元素有排序需求，可以将 Set 转换为 Sorted Set。Sorted Set 中的每个元素都有一个分数（score），可以根据分数进行排序和范围查询。这样可以更加高效地处理大量的元素。

### Redis内存不够了怎么办

1. **设置合理的过期时间**：对于不再需要的键值对，可以通过设置合理的过期时间来自动释放内存。这样可以避免内存被长时间占用。
2. **持久化到磁盘**：使用 Redis 的持久化功能将部分数据存储到磁盘中。这样可以释放内存，并且在需要时可以从磁盘加载回内存。可以选择使用 RDB 持久化或 AOF 持久化，或者两者结合使用。
3. **使用内存淘汰策略**：当内存不足时，Redis 提供了多种内存淘汰策略，可根据实际情况选择合适的策略。例如，可以设置使用 LRU（最近最少使用）策略或 LFU（最近最不常用）策略等来淘汰不常用的数据。
4. **分片或集群化**：如果单个 Redis 实例无法满足需求，可以考虑将数据进行分片或搭建 Redis 集群。将数据分散到多个 Redis 节点上，提高整体的内存处理能力。

### Redis 事务的概念

1. Redis 事务中如果有某一条命令执行失败，之前的命令**不会回滚**，其后的命令仍然会被继续执行。鉴于这个原因，所以说 Redis 的事务严格意义上来说是不具备原子性的。
2. Redis 事务中所有命令都会序列化、按顺序地执行。事务在执行的过程中，**不会被其他客户端发送来的命令请求所打断**。
3. 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语占都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行 EXEC 命令之后，那么该事务中的所有命今都会被服务器执行
4. Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有**隔离性**的。

### Redis 事务相关指令

- WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set (CAS) 行为，可以监控一个或多个键，**一旦事务执行前有一个键被修改(或删除)，之后的事务就不会执行**，监控一直持续到 EXEC 命令

- MULTI 命令用于**开启一个事务**，它总是返回OK。MULTI 执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个**队列**中，当 EXEC 命令被调用时，所有队列中的命令才会被执行。

- EXEC: 执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。

  通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退出。

- UNWATCH 命令可以取消 watch 对所有 key 的监控。

### Redis 集群方式，哨兵选举过程

- 单机 Redis 的风险与问题

  问题一：机器故障

  - 硬盘故障，系统崩溃
  - 本质：数据丢失，可能对业务造成灾难性打击

  问题二：容量瓶颈

  - 内存不足，一台 Redis 内存是有限的

- Redis 集群方式

  1. 主从模式：
     建立连接阶段-建立 slave 到 master 的连接，使 master 能够识别 slave，并保存 slave 端口号
     数据同步阶段-在 slave 初次连接 master 后，复制 master 中的所有数据到slave
     命令传播阶段-当 master 数据库状态被修改后，导致主从服务器数据库状态不一致，此时需要让主从数据同步到一致的状态
  2. 哨兵模式（Sentinel Mode）：在哨兵模式下，Redis集群中会有若干个哨兵节点监控主节点和从节点的状态。当主节点不可用时，哨兵会自动进行选举，选出一个新的主节点，并将其他节点设置为从节点。哨兵会通过互相交流来达成共识，并使用选举算法选出新的主节点。
  3. Cluster 模式（Cluster Mode）：在 Cluster 模式下，Redis 集群中的节点被组织成多个揭示槽（slot）的哈希槽。数据根据键名的哈希值被分配到对应的揭示槽上。Redis Cluster 使用 Gossip 协议进行节点之间的通信，通过交换信息来达成一致，并动态调整节点分布，保证高可用性和扩展性。

- 哨兵选举过程

  1. 如果一个哨兵节点确定主节点不可用，它会向其他哨兵节点发送SENTINEL is-master-down-by-addr命令，请求其他哨兵节点确认主节点的不可用情况。
  2. 如果多数的哨兵节点都确认主节点不可用，那么它们会通过选举算法选择一个新的主节点，并将其他节点设置为从节点。
  3. 当选出新的主节点后，哨兵节点会使用SENTINEL failover命令通知其他Redis实例进行主从切换

### 主从复制的原理

- 主从架构的核心原理

  当启动一个slave node的时候，它会发送一个PSYNC命令给master node

  如果这是 slave node 重新连接 master node，那么master node仅仅会复制给slave 部分缺少的数据;否则如果是 slave node 第一次连接 master node，那么会触发一次 full resynchronization

  开始 full resynchronization 的时候，master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命今缓存在内存中。RDB 文件生成完毕之后，master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后 master 会将内存中缓存的写命令发送给 slave，slave 也会同步这些数据。

  slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，master如果发现有多人 slave node 都来重新连接，仅仅会启动一个 rdb save 操作，用一份数据服务所有 slave node。

- 主从复制的断点续传

  从Redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份

  master node 会在内存中常见一个 backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的 replica offset开始继续复制

  但是如果没有找到对应的offset，那么就会执行一次resynchronization

- 无磁盘化复制

  master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了

  repl-diskless-sync repldiskless-sync-delay，等待一定时长再开始复制，因为要等更多slave重新连按过来

- 过期 key 处理

  slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。

### Redis 实现分布式锁

1. 加锁
   使用 setnx 来加锁。key是锁的唯一标识，按业务来决定命名，value这里设置为test。`setnx key "mutex"`

   当一个线程执行 setnx 返回1，说明 key 原本不存在，该线程成功得到了锁;当一个线程执行 setnx 返回0说明 key 已经存在，该线程抢锁失败。

2. 解锁

   释放锁的最简单方式就是执行 del 指令。`del key`

3. 锁超时

   锁超时知道的是: 如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式地释放锁，这块资源将会永远被锁住。
   所以，setnx 的 key 必须设置一个超时时间，以保证即使没有被显式释放，这把锁也要在一段时间后自动释放。setnx 不支持超时参数，所以需要额外指今。

   `expire key 30`

4. 如果先加锁再设置超时时间，会有原子性问题，使用`SET key value [Ex seconds][px mi1iseconds] [Nx|xX]`直接设置超时时间

## RabbitMQ消息队列

### RabbitMQ和kafka区别

RabbitMQ和Kafka是两种常用的消息队列系统，它们在设计和功能上有一些区别。下面是RabbitMQ和Kafka之间的主要区别：

1. 数据处理模式：
   - RabbitMQ：RabbitMQ基于**传统的消息队列模型**，它使用生产者-消费者模式将消息通过中间件传递。消息发布者（生产者）将消息发送到队列，然后由消息订阅者（消费者）从队列中接收和处理消息。
   - Kafka：Kafka采用**发布-订阅模型**，它通过主题（topic）将消息持久化到日志文件中。**消息发布者将消息写入主题的分区中**，而消息订阅者可以随时从指定的**偏移量**开始消费消息。
2. 数据保证：
   - RabbitMQ：RabbitMQ提供可靠性消息传递（reliable message delivery），支持事务和消息确认机制。消费者在接收到消息后需要发送确认回执，以确保消息被正确处理。
   - Kafka：Kafka通过分布式日志存储和复制机制来保证数据的持久性和高可用性。它将消息持久化到磁盘中，并且可以在集群中进行复制，从而避免数据丢失。
3. 消息传输延迟：
   - RabbitMQ：RabbitMQ在传输消息时通常具有**较低的延迟**，适合对实时性要求较高的应用场景。
   - Kafka：由于Kafka采用了批量写入和顺序写入的方式，一般具有较低的写入延迟，但**读取消息可能会有一定的延迟**。相对于RabbitMQ，Kafka更注重吞吐量和持久性。

综上所述，选择RabbitMQ还是Kafka取决于具体的应用场景和需求。如果需要实时性较高、单播或广播的消息传递，可以选择RabbitMQ；如果需要大规模、高吞吐量的流式数据处理，可以选择Kafka。

### 为什么Kafka吞吐量高

1. 分布式架构：Kafka采用分布式的设计，可以将负载和数据分布到多个服务器上。这使得它可以通过横向扩展（即增加服务器数量）来提高整体吞吐量。通过增加分区和副本等方式将数据分散存储和处理，进一步提升了系统的并发性和容错性。
2. 顺序写入与零拷贝：Kafka将消息以连续的方式追加写入日志文件（log segments），实现了高效的顺序写入。这种顺序写入的方式相对于随机写入可以获得更好的磁盘性能。同时，Kafka还采用零拷贝技术，减少了数据在内核空间和用户空间之间的复制，提高了存储和检索的效率。
3. 批量发送和压缩：Kafka支持批量发送消息，即生产者可以一次性发送多条消息，减少网络开销。此外，Kafka还提供了消息压缩功能，可以在网络传输和磁盘存储上进行有效压缩，减少了数据的大小，提高网络传输和磁盘IO的效率。
4. 集群式消费和水平扩展：Kafka使用消费者组（consumer group）的方式进行消息消费。消费者组可以订阅相同的主题，每个消费者负责处理一部分分区的消息。这种集群式消费模型使得多个消费者可以并行地处理消息，从而提高吞吐量。同时，通过增加消费者或增加分区等方式，可以水平扩展系统的处理能力。
5. 高效的消息存储和检索：Kafka使用了一种基于磁盘的持久化存储方式，使得可以长时间保留大量的消息。它采用了索引和位移的方式来管理消息，可以快速地定位和检索消息。这种高效的存储和检索机制使得Kafka能够应对高吞吐量的数据流。

## 微服务

### 分布式锁使用场景

在单体项目中jvm中的锁即可完成需要，但是[微服务](https://so.csdn.net/so/search?q=微服务&spm=1001.2101.3001.7020)、分布式环境下，同一个服务可能部署在多台服务器上，多个jvm之间无法通过常用的jvm锁来完成同步操作，需要借用分布式锁来完成上锁、释放锁。例如在订单服务中，我们需要根据日期来生成订单号流水，就有可能产生相同的时间日期，从而出现重复订单号。

### zookeeper分布式锁实现原理

1、zookeeper中规定，在同一时刻，不能有多个客户端创建同一个节点，我们可以利用这个特性实现分布式锁。zookeeper临时节点只在session生命周期存在，session一结束会自动销毁。

2、watcher机制，在代表锁资源的节点被删除，即可以触发watcher解除阻塞重新去获取锁，这也是zookeeper分布式锁较其他分布式锁方案的一大优势。
